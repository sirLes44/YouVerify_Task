{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-02T15:35:57.423872Z",
     "iopub.status.busy": "2023-08-02T15:35:57.423000Z",
     "iopub.status.idle": "2023-08-02T15:36:09.418634Z",
     "shell.execute_reply": "2023-08-02T15:36:09.417366Z",
     "shell.execute_reply.started": "2023-08-02T15:35:57.423823Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.combine import SMOTETomek\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I performed data exploration and read the data description document, the following were discovered;\n",
    "* The Dataset is inbalanced.\n",
    "* There are columns containing arbitrary values.\n",
    "* Some columns pose a data leakage problem.\n",
    "* The target features column has some missing values\n",
    "* Missing values are very minimal (<2%).\n",
    "* There are curropt values, typos, and wrong dtypes.\n",
    "\n",
    "These issues will now be addressed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confirm Dataset is imbalanced**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly I need to check if the dataset in imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T15:36:17.380378Z",
     "iopub.status.busy": "2023-08-02T15:36:17.379470Z",
     "iopub.status.idle": "2023-08-02T15:36:26.015126Z",
     "shell.execute_reply": "2023-08-02T15:36:26.013814Z",
     "shell.execute_reply.started": "2023-08-02T15:36:17.380335Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P I F     739609\n",
       "CHGOFF    157558\n",
       "Name: MIS_Status, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data into dataframe\n",
    "df = pd.read_csv(\"SBAnational.csv\", low_memory = False)\n",
    "# Check the value counts of the target variable\n",
    "df.MIS_Status.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ration of  `P I F` (Paid if full) to `CHGOFF` (Charged off) loans is ~ 1 : 5, there is clear inbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Preprocessing and Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Data**\n",
    "\n",
    "The following function will load the data. This process will include reading the data, drop predetermined columns, clean and transform the data, handle missing values, and factorize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T15:36:42.428311Z",
     "iopub.status.busy": "2023-08-02T15:36:42.427870Z",
     "iopub.status.idle": "2023-08-02T15:36:42.435014Z",
     "shell.execute_reply": "2023-08-02T15:36:42.433637Z",
     "shell.execute_reply.started": "2023-08-02T15:36:42.428276Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # Read data\n",
    "    df = pd.read_csv(\"SBAnational.csv\", low_memory = False)\n",
    "    # PREPROCESSING\n",
    "    # Function to drop missing values and arbitrary + data leakage columns\n",
    "    df = drop_cols_and_missing_vals(df)\n",
    "    # Function to clean and transform data\n",
    "    df = clean_and_transform(df)\n",
    "    # Function to factorize categorical features\n",
    "    # df = factorizer(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Handling Missing Values and Arbitrary + Data Leakage Columns**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Arbitrary and Data Leakage Columns:**\n",
    "\n",
    "* The `LoanNr_ChkDgt` column holds the loan identification number while the `Name` column is the name of the borrower. These columns are arbitrary and hence not helpful.\n",
    "* `ChgOffDate` is the date a loan was charged off. Clearly only charged off loans have a value in this column. `ChgOffPrinGr` is the amount that was charged off. Again, only charged of loans have a value here. `BalanceGross` is the outstanding balance on a loan. All charged off loans have a $0 value. These columns will cause data leakage problems and thus need to be dropped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T15:36:37.791497Z",
     "iopub.status.busy": "2023-08-02T15:36:37.791043Z",
     "iopub.status.idle": "2023-08-02T15:36:37.797775Z",
     "shell.execute_reply": "2023-08-02T15:36:37.796223Z",
     "shell.execute_reply.started": "2023-08-02T15:36:37.791461Z"
    }
   },
   "outputs": [],
   "source": [
    "arbitrary_cols = ['LoanNr_ChkDgt', 'Name']\n",
    "data_leakage_cols = ['ChgOffDate', 'ChgOffPrinGr', 'BalanceGross']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing Values:**\n",
    "\n",
    "Calculate Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T15:36:54.596331Z",
     "iopub.status.busy": "2023-08-02T15:36:54.595880Z",
     "iopub.status.idle": "2023-08-02T15:36:58.660490Z",
     "shell.execute_reply": "2023-08-02T15:36:58.659251Z",
     "shell.execute_reply.started": "2023-08-02T15:36:54.596297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Size of Dataset</th>\n",
       "      <td>899164.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Missing Values</th>\n",
       "      <td>14780.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Missing Values %</th>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Count\n",
       "Size of Dataset   899164.00\n",
       "Missing Values     14780.00\n",
       "Missing Values %       1.64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns = arbitrary_cols + data_leakage_cols, inplace=True)\n",
    "missing_vals = df.isnull().sum()\n",
    "isnull_values = round((missing_vals[missing_vals > 0].sum() / len(df)) * 100, 2)\n",
    "dataset_size = len(df)\n",
    "missing_values_percentage = pd.DataFrame(data = {'Count': [dataset_size, missing_vals[missing_vals > 0].sum(),\\\n",
    "                                         isnull_values]}, index = ['Size of Dataset', 'Missing Values', 'Missing Values %'])\n",
    "missing_values_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The missing values make up less than 2% of the dataset. Considering the size of the dataset (~ 900k),this seems negligible. The missing values will be dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to drop missing values and arbitrary + data leakage columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T15:37:41.829641Z",
     "iopub.status.busy": "2023-08-02T15:37:41.829167Z",
     "iopub.status.idle": "2023-08-02T15:37:41.838328Z",
     "shell.execute_reply": "2023-08-02T15:37:41.837271Z",
     "shell.execute_reply.started": "2023-08-02T15:37:41.829609Z"
    }
   },
   "outputs": [],
   "source": [
    "def drop_cols_and_missing_vals(df):\n",
    "    # Drop arbitrary and data leakage columns\n",
    "    df.drop(columns=arbitrary_cols + data_leakage_cols, inplace = True)\n",
    "    # Drop missing values from Target variable column\n",
    "    df.dropna(subset = 'MIS_Status', inplace=True, axis=0)\n",
    "    # Drop missing values\n",
    "    df.dropna(inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean and Transform Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From reading the data description document and performing some data exploration, it was found that substantial data cleaning needs to be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T15:40:26.796602Z",
     "iopub.status.busy": "2023-08-02T15:40:26.796108Z",
     "iopub.status.idle": "2023-08-02T15:40:26.814821Z",
     "shell.execute_reply": "2023-08-02T15:40:26.813334Z",
     "shell.execute_reply.started": "2023-08-02T15:40:26.796568Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# These columns contain norminal data presented as numeric data, mapping is required to reflect their norminal categorical nature\n",
    "# Also map the target variable from categorical to binary values\n",
    "map_cols = {'NAICS': {11: 'Agriculture', 21: 'Mining', 22: 'Utilities', 23: 'Construction', 31: 'Manufacturing', 32: 'Manufacturing',\\\n",
    "              33: 'Manufacturing', 42: 'Wholesale', 44: 'Retail', 45: 'Retail', 48: 'Transportation', 49: 'Transportation', 51: 'Information', \\\n",
    "              52: 'Finance', 53: 'RealEstate', 54: 'Professional', 55: 'Management', 56: 'AdminWasteRem', 61: 'Education', 62: 'HealthCare', \\\n",
    "              71: 'Arts', 72: 'Accommodation', 81: 'OtherServices', 92: 'PublicAdmin'},\\\n",
    "           'NewExist': {0: 'Undefined', 1: 'Existing', 2: 'New'}, 'UrbanRural': {0: 'Undefined', 1: 'Urban', 2: 'Rural'}, \\\n",
    "           'MIS_Status': {'P I F': 0, 'CHGOFF': 1},}\n",
    "yesno_cols = ['RevLineCr', 'LowDoc']\n",
    "# These columns hold continous numerical data but have $ and comma characters that need to be removed\n",
    "currency_cols = ['DisbursementGross', 'GrAppv', 'SBA_Appv']\n",
    "\n",
    "\n",
    "\n",
    "def clean_and_transform(df):\n",
    "    # Some values in ApprovalFY column have typos that need to be corrected\n",
    "    df.ApprovalFY = df.ApprovalFY.replace({'1976A': 1976})\n",
    "    # Map all other categorical columns the above map_cols, yesno_cols and currency_cols\n",
    "    for column in df.columns:\n",
    "        if column == 'FranchiseCode':\n",
    "            df[column] = df[column].apply(lambda x: 0 if x == 0 or x == 1 else 1)\n",
    "        elif column == 'NAICS':\n",
    "            df[column] = df[column].apply(lambda x: 'Other' if x == 0 else map_cols[column][int(str(x)[:2])])\n",
    "        elif column in yesno_cols:\n",
    "            df[column] = df[column].apply(lambda x: x if x == 'Y' or x == 'N' else 'Unknown')\n",
    "        elif column in currency_cols:\n",
    "            df[column] = df[column].map(lambda x: int(x[1:-4].replace(',','')))\n",
    "        elif column in map_cols.keys():\n",
    "            df[column] = df[column].map(map_cols[column])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Factorize**\n",
    "\n",
    "This function will factorize all categorical features in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T14:40:03.930825Z",
     "iopub.status.busy": "2023-08-02T14:40:03.930162Z",
     "iopub.status.idle": "2023-08-02T14:40:03.936150Z",
     "shell.execute_reply": "2023-08-02T14:40:03.934967Z",
     "shell.execute_reply.started": "2023-08-02T14:40:03.930790Z"
    }
   },
   "outputs": [],
   "source": [
    "def factorizer(df):\n",
    "    for colname in df.select_dtypes('object'):\n",
    "        df[colname], _ = df[colname].factorize()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Feature Utility Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mutual Information (MI) will be used to measure the relationship between the features and the target variable.\n",
    "This will help in determing which features will be helpful and which can be dropped.\n",
    "\n",
    "The function defined below will generate the MI scores for the features to determine their utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T15:42:19.253026Z",
     "iopub.status.busy": "2023-08-02T15:42:19.252543Z",
     "iopub.status.idle": "2023-08-02T15:42:19.481382Z",
     "shell.execute_reply": "2023-08-02T15:42:19.479983Z",
     "shell.execute_reply.started": "2023-08-02T15:42:19.252991Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def make_mi_scores(df):\n",
    "    df = factorizer(df)\n",
    "    X = df.copy()\n",
    "    y = X.pop('MIS_Status')\n",
    "    # All discrete features should now have integer dtypes\n",
    "    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n",
    "    # Get MI scores\n",
    "    mi_scores = mutual_info_classif(X, y, discrete_features=discrete_features)\n",
    "    # Convert to a Series object\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T15:42:24.857172Z",
     "iopub.status.busy": "2023-08-02T15:42:24.856711Z",
     "iopub.status.idle": "2023-08-02T15:42:29.583655Z",
     "shell.execute_reply": "2023-08-02T15:42:29.582101Z",
     "shell.execute_reply.started": "2023-08-02T15:42:24.857140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term                 0.261964\n",
      "DisbursementGross    0.104011\n",
      "DisbursementDate     0.087544\n",
      "ApprovalDate         0.073108\n",
      "ApprovalFY           0.066067\n",
      "SBA_Appv             0.060602\n",
      "Bank                 0.058030\n",
      "Zip                  0.039582\n",
      "GrAppv               0.035734\n",
      "City                 0.034859\n",
      "RetainedJob          0.026046\n",
      "UrbanRural           0.024535\n",
      "BankState            0.019807\n",
      "NAICS                0.014742\n",
      "NoEmp                0.008602\n",
      "CreateJob            0.007551\n",
      "State                0.006458\n",
      "RevLineCr            0.006196\n",
      "LowDoc               0.003942\n",
      "NewExist             0.000242\n",
      "FranchiseCode        0.000123\n",
      "Name: MI Scores, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = load_data()\n",
    "mi_scores = make_mi_scores(df)\n",
    "print(mi_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All features have MI scores greater than zero, although some scores are quite minimal. Since there are no zero scores, all features will be kept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final part of this step is to load the Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few new features were created with the hope that they would improve the informativeness of the dataset.\n",
    "* A possibly useful feature is the ratio of payment term in months `Term` to the loam amount `GrAppv`.\n",
    "* Another interesting feature could be the ratio of the SBA insured loan portion `SBA_Appv` to the loan amount `GrAppv`.\n",
    "* A third possibly useful feature could be the ratio of the payment term in months `Term` to the SBA insured loan portion `SBA_Appv`.\n",
    "\n",
    "The function defined below will create these new features and add them to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_features(df):\n",
    "    X_new = pd.DataFrame()\n",
    "    X_new['feature_1'] = df.Term / df.GrAppv\n",
    "    X_new['feature_2'] = df.SBA_Appv / df.GrAppv\n",
    "    X_new['feature_3'] = df.Term / df.SBA_Appv\n",
    "    df = df.join(X_new)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now to check if the added features provide any added information by virtue of their MI scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term                 0.261964\n",
      "feature_1            0.145049\n",
      "feature_3            0.142019\n",
      "DisbursementGross    0.104011\n",
      "DisbursementDate     0.087544\n",
      "ApprovalDate         0.073108\n",
      "ApprovalFY           0.066067\n",
      "SBA_Appv             0.060602\n",
      "Bank                 0.058030\n",
      "feature_2            0.049165\n",
      "Zip                  0.039582\n",
      "GrAppv               0.035734\n",
      "City                 0.034859\n",
      "RetainedJob          0.026046\n",
      "UrbanRural           0.024535\n",
      "BankState            0.019807\n",
      "NAICS                0.014742\n",
      "NoEmp                0.008602\n",
      "CreateJob            0.007551\n",
      "State                0.006458\n",
      "RevLineCr            0.006196\n",
      "LowDoc               0.003942\n",
      "NewExist             0.000242\n",
      "FranchiseCode        0.000123\n",
      "Name: MI Scores, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = add_new_features(df)\n",
    "mi_scores = make_mi_scores(df)\n",
    "print(mi_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Their MI scores imply that they are informative, hence they wiil be kept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A function to load the final features, which will include the new features from the feature engineering step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_features():\n",
    "    df = load_data()\n",
    "    df = add_new_features(df)\n",
    "    df = factorizer(df)\n",
    "    X = df.copy()\n",
    "    y = X.pop('MIS_Status')\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load final features\n",
    "X, y = final_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T08:39:41.332119Z",
     "iopub.status.busy": "2023-08-02T08:39:41.331683Z",
     "iopub.status.idle": "2023-08-02T08:39:41.638827Z",
     "shell.execute_reply": "2023-08-02T08:39:41.637608Z",
     "shell.execute_reply.started": "2023-08-02T08:39:41.332087Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split dataset into train and test sets with train set = 80% and test set = 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model - XGBoost**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost is known for its accuracy and efficiency. It is a good choice for dealing with imbalanced datasets \n",
    "because it can be fine-tuned to focus on the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation Metric - Confusion Matrix and Classification Report**\n",
    "\n",
    "* Confusion Matrix was chosing because it makes it easy to see wrong classifications numerically. In this case with regards to this dataset, more focus should be on the True Positives and False Negatives. This is because the aim is to identify loanees who will default (True Positives). As such, minimizing the number of defaulters that are wrongfully classified as no risk (False Negatives) is also of importance.\n",
    "* Classification Report was chosen because focuses on precision and recall. The precision (percentage of correct positive predictions relative to total positive predictions) should always be evaluated. However, regarding the aim of this task, the recall (percentage of correct positive predictions relative to total actual positives) is important.\n",
    "\n",
    "Using these metrics can help train the model to produce better results regarding default prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the best results, hyperparameter tuning was done using GridSearchCV. The best parameters found can be seen in the params dictionary below. Of particular interest was the `scale_pos_weight` parameter. This parameter assigns weights to the classes and can be used to apply more weight to the minority class, emphasizing its importance. In this case, the model performed best with this parameter set to its default(1), implying that the imbalance in the dataset cannot be addressed using this parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for XGBoost\n",
    "params = {\n",
    "        'learning_rate': 0.25,\n",
    "        'n_estimators': 100,\n",
    "        'objective':'binary:logistic',\n",
    "        'colsample_bytree': 0.9,\n",
    "        'max_depth': 11,\n",
    "        'scale_pos_weight': 1\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was trained and evaluated using the parameter grid above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[142820   3161]\n",
      " [  4150  27120]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98    145981\n",
      "           1       0.90      0.87      0.88     31270\n",
      "\n",
      "    accuracy                           0.96    177251\n",
      "   macro avg       0.93      0.92      0.93    177251\n",
      "weighted avg       0.96      0.96      0.96    177251\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(**params)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision and recall for the Negative class is very high, this is to be expected as this is the majority class with regards to the inbalance in the dataset.\n",
    "The precision and recall for the positive class are not as high as those for the Negative class, understandable as this is the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim now is to try and mitigate the effects of the inbalance and consequently improve the recall of the true positives class without sacrificing too much precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Improve model by mitigating dataset imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Under-Sampling, Over-Sampling & SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to try improve the model performance by accounting for the inbalance in the data, the following  Resampling techniques were performed;\n",
    "* **Under-Sampling**: This reduces the majority class to be more at par with the minority class.\n",
    "* **Over-Sampling**: This copies the minority class and uses these copies to increase the class size to be more at par with the majority class.\n",
    "* **SMOTE**: This technique oversamples the minority class by creating synthetic data points between existing minority class points.\n",
    "\n",
    "The resampling rate I used here is 50% to resample the respective class by halve the size of the other class.\n",
    "The model was then trained and evaluated on each of the resampled datasets and the results were compared. See code block below (the code block is in markdown because it requires significant time to execute)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-01T18:00:04.005300Z",
     "iopub.status.busy": "2023-08-01T18:00:04.004952Z",
     "iopub.status.idle": "2023-08-01T20:52:08.468819Z",
     "shell.execute_reply": "2023-08-01T20:52:08.467912Z",
     "shell.execute_reply.started": "2023-08-01T18:00:04.005275Z"
    }
   },
   "source": [
    "```\n",
    "sample = 0.5\n",
    "imbl_dict = {\n",
    "    'Under-Sampling': NearMiss(sampling_strategy=sample),\n",
    "    'Over-Sampling': RandomOverSampler(sampling_strategy=sample),\n",
    "    'SMOTE': SMOTETomek(sampling_strategy=sample)\n",
    "}\n",
    "\n",
    "for key in imbl_dict.keys():\n",
    "    sampler = imbl_dict[key]\n",
    "    X_train_s, y_train_s = sampler.fit_resample(X_train, y_train)\n",
    "    model = xgb.XGBClassifier()\n",
    "    model.fit(X_train_s, y_train_s)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(key + ' Result')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are the results of the above code block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Under-Sampling Result\n",
    "[[120635  25346]\n",
    " [  2450  28820]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.98      0.83      0.90    145981\n",
    "           1       0.53      0.92      0.67     31270\n",
    "\n",
    "    accuracy                           0.84    177251\n",
    "   macro avg       0.76      0.87      0.79    177251\n",
    "weighted avg       0.90      0.84      0.86    177251\n",
    "\n",
    "Over-Sampling Result\n",
    "[[140188   5793]\n",
    " [  2845  28425]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.98      0.97      0.97    145981\n",
    "           1       0.86      0.90      0.88     31270\n",
    "\n",
    "    accuracy                           0.95    177251\n",
    "   macro avg       0.91      0.93      0.92    177251\n",
    "weighted avg       0.95      0.95      0.95    177251\n",
    "\n",
    "SMOTE Result\n",
    "[[141793   4188]\n",
    " [  4515  26755]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.97      0.97      0.97    145981\n",
    "           1       0.86      0.86      0.86     31270\n",
    "\n",
    "    accuracy                           0.95    177251\n",
    "   macro avg       0.92      0.91      0.92    177251\n",
    "weighted avg       0.95      0.95      0.95    177251\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[141421   4560]\n",
      " [  3117  28153]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97    145981\n",
      "           1       0.86      0.90      0.88     31270\n",
      "\n",
      "    accuracy                           0.96    177251\n",
      "   macro avg       0.92      0.93      0.93    177251\n",
      "weighted avg       0.96      0.96      0.96    177251\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "resampler = RandomOverSampler(sampling_strategy = 0.5)\n",
    "X_train, y_train = resampler.fit_resample(X_train, y_train)\n",
    "\n",
    "model = xgb.XGBClassifier(**params)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above results, the method to go with is Over-Sampling. This is because it is the only one that significantly increases recall without compromising precision excessively.\n",
    "\n",
    "The final model will be trained on Over-Sampled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.25, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=11, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = final_features()\n",
    "\n",
    "resampler = RandomOverSampler(sampling_strategy = 0.5)\n",
    "X_train, y_train = resampler.fit_resample(X, y)\n",
    "\n",
    "model = xgb.XGBClassifier(**params)\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save_model(\"model.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
